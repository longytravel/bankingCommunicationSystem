"""
Smart Voice Note Generator - With Audio Generation and Multi-Language Support
Generates actual audio files that can be played in the app
"""

import os
import json
import re
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path
import hashlib

# Environment setup
from dotenv import load_dotenv
load_dotenv()

# AI imports
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    print("âš ï¸ Anthropic not available - using simulation mode")

# TTS imports
try:
    from openai import OpenAI
    OPENAI_TTS_AVAILABLE = True
except ImportError:
    OPENAI_TTS_AVAILABLE = False
    print("âš ï¸ OpenAI TTS not available")

try:
    import pyttsx3
    PYTTSX3_AVAILABLE = True
except ImportError:
    PYTTSX3_AVAILABLE = False
    print("âš ï¸ pyttsx3 not available - no fallback TTS")

# Import SharedContext
import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.core.shared_brain import SharedContext, PersonalizationLevel
    SHARED_BRAIN_AVAILABLE = True
except ImportError:
    SHARED_BRAIN_AVAILABLE = False
    print("âš ï¸ Could not import SharedContext")

@dataclass
class VoiceResult:
    """Result from voice note generation with audio file"""
    content: str  # The script/text for the voice note
    duration_estimate: float  # Estimated duration in seconds
    word_count: int
    speaking_pace: str  # slow, normal, fast
    tone_markers: List[str]  # Emotional tone markers
    personalization_elements: List[str]
    emphasis_words: List[str]  # Words to emphasize
    language: str
    generation_method: str
    processing_time: float
    quality_score: float
    audio_file_path: Optional[str] = None  # Path to generated audio file
    audio_format: str = "mp3"
    tts_engine_used: str = "none"  # openai, pyttsx3, or none

class SmartVoiceGenerator:
    """
    Smart Voice Note Generator with Audio Generation
    Creates both scripts and playable audio files
    """
    
    # ============== VOICE CONFIGURATION WITH AUDIO ==============
    VOICE_CONFIG = {
        'audio': {
            'output_dir': 'output/voice_notes',
            'format': 'mp3',
            'sample_rate': 24000,
            'quality': 'high'
        },
        'tts': {
            'openai': {
                'model': 'tts-1-hd',  # Higher quality model
                'voices': {
                    'English': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Spanish': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'French': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'German': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Italian': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Portuguese': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Polish': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Dutch': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Russian': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Japanese': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Chinese': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Korean': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Arabic': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Hindi': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'},
                    'Turkish': {'DIGITAL': 'nova', 'ASSISTED': 'alloy', 'TRADITIONAL': 'onyx'}
                },
                'speed_settings': {
                    'slow': 0.85,
                    'normal': 1.0,
                    'fast': 1.15
                }
            },
            'pyttsx3': {
                'rate': 150,  # Words per minute
                'volume': 0.9
            }
        },
        'durations': {
            'max': 120,  # Maximum 2 minutes
            'min': 15,   # Minimum 15 seconds
            'optimal': 45  # Ideal 45 seconds
        },
        'greetings': {
            'English': {
                'DIGITAL': 'Hi {name}, this is {bank_rep} from Lloyds',
                'ASSISTED': 'Hello {name}, this is {bank_rep} calling from Lloyds Bank',
                'TRADITIONAL': 'Good {time_of_day} {title} {last_name}, this is {bank_rep} from Lloyds Banking Group'
            },
            'Spanish': {
                'DIGITAL': 'Hola {name}, soy {bank_rep} de Lloyds',
                'ASSISTED': 'Buenos dÃ­as {name}, le llama {bank_rep} del Banco Lloyds',
                'TRADITIONAL': 'Buenos {time_of_day} {title} {last_name}, le habla {bank_rep} del Grupo Bancario Lloyds'
            },
            'French': {
                'DIGITAL': 'Salut {name}, c\'est {bank_rep} de Lloyds',
                'ASSISTED': 'Bonjour {name}, c\'est {bank_rep} de la Banque Lloyds',
                'TRADITIONAL': 'Bonjour {title} {last_name}, c\'est {bank_rep} du Groupe Bancaire Lloyds'
            },
            'German': {
                'DIGITAL': 'Hallo {name}, hier ist {bank_rep} von Lloyds',
                'ASSISTED': 'Guten Tag {name}, hier spricht {bank_rep} von der Lloyds Bank',
                'TRADITIONAL': 'Guten {time_of_day} {title} {last_name}, hier spricht {bank_rep} von der Lloyds Banking Group'
            },
            'Italian': {
                'DIGITAL': 'Ciao {name}, sono {bank_rep} di Lloyds',
                'ASSISTED': 'Buongiorno {name}, sono {bank_rep} della Banca Lloyds',
                'TRADITIONAL': 'Buongiorno {title} {last_name}, sono {bank_rep} del Gruppo Bancario Lloyds'
            },
            'Portuguese': {
                'DIGITAL': 'OlÃ¡ {name}, aqui Ã© {bank_rep} do Lloyds',
                'ASSISTED': 'Bom dia {name}, fala {bank_rep} do Banco Lloyds',
                'TRADITIONAL': 'Bom {time_of_day} {title} {last_name}, fala {bank_rep} do Grupo BancÃ¡rio Lloyds'
            },
            'Polish': {
                'DIGITAL': 'CzeÅ›Ä‡ {name}, tu {bank_rep} z Lloyds',
                'ASSISTED': 'DzieÅ„ dobry {name}, mÃ³wi {bank_rep} z Banku Lloyds',
                'TRADITIONAL': 'DzieÅ„ dobry {title} {last_name}, mÃ³wi {bank_rep} z Grupy Bankowej Lloyds'
            },
            'Dutch': {
                'DIGITAL': 'Hoi {name}, met {bank_rep} van Lloyds',
                'ASSISTED': 'Goedendag {name}, u spreekt met {bank_rep} van Lloyds Bank',
                'TRADITIONAL': 'Goedendag {title} {last_name}, u spreekt met {bank_rep} van Lloyds Banking Group'
            },
            'Chinese': {
                'DIGITAL': 'ä½ å¥½{name}ï¼Œæˆ‘æ˜¯åŠ³åŸƒå¾·é“¶è¡Œçš„{bank_rep}',
                'ASSISTED': 'æ‚¨å¥½{name}ï¼Œæˆ‘æ˜¯åŠ³åŸƒå¾·é“¶è¡Œçš„{bank_rep}',
                'TRADITIONAL': 'æ‚¨å¥½{title}{last_name}ï¼Œæˆ‘æ˜¯åŠ³åŸƒå¾·é“¶è¡Œé›†å›¢çš„{bank_rep}'
            },
            'Japanese': {
                'DIGITAL': 'ã“ã‚“ã«ã¡ã¯{name}ã•ã‚“ã€ãƒ­ã‚¤ã‚ºã®{bank_rep}ã§ã™',
                'ASSISTED': 'ã“ã‚“ã«ã¡ã¯{name}æ§˜ã€ãƒ­ã‚¤ã‚ºéŠ€è¡Œã®{bank_rep}ã¨ç”³ã—ã¾ã™',
                'TRADITIONAL': '{name}æ§˜ã€ãƒ­ã‚¤ã‚ºãƒ»ãƒãƒ³ã‚­ãƒ³ã‚°ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—ã®{bank_rep}ã¨ç”³ã—ã¾ã™'
            },
            'Arabic': {
                'DIGITAL': 'Ù…Ø±Ø­Ø¨Ø§Ù‹ {name}ØŒ Ø£Ù†Ø§ {bank_rep} Ù…Ù† Ù„ÙˆÙŠØ¯Ø²',
                'ASSISTED': 'Ø£Ù‡Ù„Ø§Ù‹ {name}ØŒ Ù…Ø¹Ùƒ {bank_rep} Ù…Ù† Ø¨Ù†Ùƒ Ù„ÙˆÙŠØ¯Ø²',
                'TRADITIONAL': 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… {title} {last_name}ØŒ Ù…Ø¹Ùƒ {bank_rep} Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ù„ÙˆÙŠØ¯Ø² Ø§Ù„Ù…ØµØ±ÙÙŠØ©'
            },
            'Hindi': {
                'DIGITAL': 'à¤¨à¤®à¤¸à¥à¤¤à¥‡ {name}, à¤®à¥ˆà¤‚ à¤²à¥‰à¤¯à¤¡à¥à¤¸ à¤¸à¥‡ {bank_rep} à¤¬à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚',
                'ASSISTED': 'à¤¨à¤®à¤¸à¥à¤¤à¥‡ {name}, à¤®à¥ˆà¤‚ à¤²à¥‰à¤¯à¤¡à¥à¤¸ à¤¬à¥ˆà¤‚à¤• à¤¸à¥‡ {bank_rep} à¤¬à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚',
                'TRADITIONAL': 'à¤¨à¤®à¤¸à¥à¤•à¤¾à¤° {title} {last_name}, à¤®à¥ˆà¤‚ à¤²à¥‰à¤¯à¤¡à¥à¤¸ à¤¬à¥ˆà¤‚à¤•à¤¿à¤‚à¤— à¤¸à¤®à¥‚à¤¹ à¤¸à¥‡ {bank_rep} à¤¬à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚'
            }
        },
        'closings': {
            'English': {
                'DIGITAL': 'Thanks for being with Lloyds. Have a great day!',
                'ASSISTED': 'Thank you for your time. If you need anything, we\'re here to help.',
                'TRADITIONAL': 'Thank you for your attention. Please don\'t hesitate to contact us.'
            },
            'Spanish': {
                'DIGITAL': 'Â¡Gracias por estar con Lloyds. Que tengas un gran dÃ­a!',
                'ASSISTED': 'Gracias por su tiempo. Si necesita algo, estamos aquÃ­ para ayudar.',
                'TRADITIONAL': 'Gracias por su atenciÃ³n. No dude en contactarnos.'
            },
            'French': {
                'DIGITAL': 'Merci d\'Ãªtre avec Lloyds. Bonne journÃ©e!',
                'ASSISTED': 'Merci pour votre temps. Si vous avez besoin de quoi que ce soit, nous sommes lÃ .',
                'TRADITIONAL': 'Merci pour votre attention. N\'hÃ©sitez pas Ã  nous contacter.'
            },
            'German': {
                'DIGITAL': 'Danke, dass Sie bei Lloyds sind. Einen schÃ¶nen Tag noch!',
                'ASSISTED': 'Vielen Dank fÃ¼r Ihre Zeit. Wenn Sie etwas brauchen, sind wir fÃ¼r Sie da.',
                'TRADITIONAL': 'Vielen Dank fÃ¼r Ihre Aufmerksamkeit. ZÃ¶gern Sie nicht, uns zu kontaktieren.'
            },
            'Italian': {
                'DIGITAL': 'Grazie per essere con Lloyds. Buona giornata!',
                'ASSISTED': 'Grazie per il suo tempo. Se ha bisogno di qualcosa, siamo qui.',
                'TRADITIONAL': 'Grazie per la sua attenzione. Non esiti a contattarci.'
            },
            'Portuguese': {
                'DIGITAL': 'Obrigado por estar com o Lloyds. Tenha um Ã³timo dia!',
                'ASSISTED': 'Obrigado pelo seu tempo. Se precisar de algo, estamos aqui.',
                'TRADITIONAL': 'Obrigado pela sua atenÃ§Ã£o. NÃ£o hesite em contactar-nos.'
            },
            'Polish': {
                'DIGITAL': 'DziÄ™kujemy za bycie z Lloyds. MiÅ‚ego dnia!',
                'ASSISTED': 'DziÄ™kujÄ™ za poÅ›wiÄ™cony czas. JeÅ›li potrzebujesz czegoÅ›, jesteÅ›my tutaj.',
                'TRADITIONAL': 'DziÄ™kujÄ™ za uwagÄ™. ProszÄ™ siÄ™ z nami kontaktowaÄ‡.'
            },
            'Dutch': {
                'DIGITAL': 'Bedankt dat u bij Lloyds bent. Fijne dag!',
                'ASSISTED': 'Bedankt voor uw tijd. Als u iets nodig heeft, staan we voor u klaar.',
                'TRADITIONAL': 'Bedankt voor uw aandacht. Aarzel niet om contact met ons op te nemen.'
            },
            'Chinese': {
                'DIGITAL': 'æ„Ÿè°¢æ‚¨é€‰æ‹©åŠ³åŸƒå¾·ã€‚ç¥æ‚¨æœ‰ç¾Žå¥½çš„ä¸€å¤©ï¼',
                'ASSISTED': 'æ„Ÿè°¢æ‚¨çš„æ—¶é—´ã€‚å¦‚æžœæ‚¨éœ€è¦ä»»ä½•å¸®åŠ©ï¼Œæˆ‘ä»¬éšæ—¶ä¸ºæ‚¨æœåŠ¡ã€‚',
                'TRADITIONAL': 'æ„Ÿè°¢æ‚¨çš„å…³æ³¨ã€‚è¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚'
            },
            'Japanese': {
                'DIGITAL': 'ãƒ­ã‚¤ã‚ºã‚’ã”åˆ©ç”¨ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚è‰¯ã„ä¸€æ—¥ã‚’ï¼',
                'ASSISTED': 'ãŠæ™‚é–“ã‚’ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ä½•ã‹ã”ã–ã„ã¾ã—ãŸã‚‰ãŠæ‰‹ä¼ã„ã„ãŸã—ã¾ã™ã€‚',
                'TRADITIONAL': 'ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚ã”ä¸æ˜Žãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚'
            },
            'Arabic': {
                'DIGITAL': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙˆÙ†Ùƒ Ù…Ø¹ Ù„ÙˆÙŠØ¯Ø². Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ ÙŠÙˆÙ…Ø§Ù‹ Ø±Ø§Ø¦Ø¹Ø§Ù‹!',
                'ASSISTED': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ÙˆÙ‚ØªÙƒ. Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Øª Ø¥Ù„Ù‰ Ø£ÙŠ Ø´ÙŠØ¡ØŒ Ù†Ø­Ù† Ù‡Ù†Ø§ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©.',
                'TRADITIONAL': 'Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ù‡ØªÙ…Ø§Ù…ÙƒÙ…. Ù„Ø§ ØªØªØ±Ø¯Ø¯ÙˆØ§ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù†Ø§.'
            },
            'Hindi': {
                'DIGITAL': 'à¤²à¥‰à¤¯à¤¡à¥à¤¸ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¹à¥‹à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦à¥¤ à¤†à¤ªà¤•à¤¾ à¤¦à¤¿à¤¨ à¤¶à¥à¤­ à¤¹à¥‹!',
                'ASSISTED': 'à¤†à¤ªà¤•à¥‡ à¤¸à¤®à¤¯ à¤•à¥‡ à¤²à¤¿à¤ à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦à¥¤ à¤…à¤—à¤° à¤†à¤ªà¤•à¥‹ à¤•à¥à¤› à¤šà¤¾à¤¹à¤¿à¤, à¤¹à¤® à¤¯à¤¹à¤¾à¤ à¤¹à¥ˆà¤‚à¥¤',
                'TRADITIONAL': 'à¤†à¤ªà¤•à¥‡ à¤§à¥à¤¯à¤¾à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¹à¤®à¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤‚à¤•à¥‹à¤š à¤¨ à¤•à¤°à¥‡à¤‚à¥¤'
            }
        }
    }
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize with API keys for AI and TTS"""
        self.api_key = api_key or os.getenv('CLAUDE_API_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.client = None
        self.openai_client = None
        self.config = self.VOICE_CONFIG
        
        # Initialize Claude for script generation
        if self.api_key and ANTHROPIC_AVAILABLE:
            self.client = anthropic.Anthropic(api_key=self.api_key)
            self.model = "claude-3-5-sonnet-20241022"
            print("âœ… Voice Generator: Claude AI ready")
        else:
            print("âš ï¸ Voice Generator: No Claude API")
        
        # Initialize OpenAI for TTS
        if self.openai_api_key and OPENAI_TTS_AVAILABLE:
            self.openai_client = OpenAI(api_key=self.openai_api_key)
            print("âœ… Voice Generator: OpenAI TTS ready")
        else:
            print("âš ï¸ Voice Generator: No OpenAI TTS")
        
        # Check pyttsx3 fallback
        if PYTTSX3_AVAILABLE:
            print("âœ… Voice Generator: pyttsx3 fallback available")
        
        # Create output directory
        self.output_dir = Path(self.config['audio']['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ðŸ“ Voice output directory: {self.output_dir}")
    
    def generate_voice_note(self, shared_context: SharedContext) -> VoiceResult:
        """Generate voice note with script AND audio file"""
        start_time = datetime.now()
        
        customer_name = shared_context.customer_data.get('name', 'Customer')
        customer_language = shared_context.customer_data.get('preferred_language', 'English')
        
        print(f"ðŸŽ™ï¸ Generating voice note for {customer_name} in {customer_language}...")
        
        # Check if voice is enabled
        voice_enabled = shared_context.channel_decisions['enabled_channels'].get('voice', False)
        if not voice_enabled:
            reason = shared_context.channel_decisions['reasons'].get('voice', 'Not enabled')
            print(f"  â­ï¸ Voice disabled: {reason}")
            return self._create_disabled_result(shared_context)
        
        # Generate the script
        if self.client:
            result = self._generate_with_ai(shared_context)
        else:
            print("  âš ï¸ No AI available, using fallback script generation")
            result = self._generate_fallback(shared_context)
        
        # Generate audio file from script
        if result.content and result.generation_method != 'disabled':
            audio_path = self._generate_audio(
                result.content,
                result.language,
                shared_context.customer_insights.segment,
                result.speaking_pace,
                shared_context.customer_data
            )
            if audio_path:
                result.audio_file_path = audio_path
                print(f"  ðŸŽµ Audio file created: {audio_path}")
        
        # Calculate processing time
        processing_time = (datetime.now() - start_time).total_seconds()
        result.processing_time = processing_time
        
        print(f"âœ… Voice note complete in {processing_time:.2f}s")
        if result.audio_file_path:
            print(f"   Audio: {result.audio_file_path}")
        print(f"   Language: {result.language}, Duration: {result.duration_estimate:.1f}s")
        
        return result
    
    def _generate_audio(
        self, 
        script: str, 
        language: str, 
        segment: str,
        pace: str,
        customer_data: Dict[str, Any]
    ) -> Optional[str]:
        """Generate audio file from script"""
        
        # Create unique filename
        customer_id = customer_data.get('customer_id', 'unknown')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"voice_{customer_id}_{language}_{timestamp}.mp3"
        filepath = self.output_dir / filename
        
        # Try OpenAI TTS first
        if self.openai_client:
            try:
                # Get voice for this language/segment
                voice = self.config['tts']['openai']['voices'].get(
                    language, {}
                ).get(segment, 'alloy')
                
                # Get speed setting
                speed = self.config['tts']['openai']['speed_settings'].get(pace, 1.0)
                
                # Generate audio
                response = self.openai_client.audio.speech.create(
                    model=self.config['tts']['openai']['model'],
                    voice=voice,
                    input=script,
                    speed=speed
                )
                
                # Save to file
                response.stream_to_file(str(filepath))
                return str(filepath)
                
            except Exception as e:
                print(f"  âŒ OpenAI TTS failed: {e}")
        
        # Fallback to pyttsx3
        if PYTTSX3_AVAILABLE:
            try:
                engine = pyttsx3.init()
                engine.setProperty('rate', self.config['tts']['pyttsx3']['rate'])
                engine.setProperty('volume', self.config['tts']['pyttsx3']['volume'])
                
                # Save to file
                engine.save_to_file(script, str(filepath))
                engine.runAndWait()
                
                return str(filepath)
                
            except Exception as e:
                print(f"  âŒ pyttsx3 TTS failed: {e}")
        
        print("  âš ï¸ No TTS engine available - no audio file generated")
        return None
    
    def _generate_with_ai(self, shared_context: SharedContext) -> VoiceResult:
        """Generate voice script with AI"""
        
        customer = shared_context.customer_data
        insights = shared_context.customer_insights
        strategy = shared_context.personalization_strategy
        content_strategy = shared_context.content_strategy
        
        # Get language and segment
        language = customer.get('preferred_language', 'English')
        segment = insights.segment
        
        # Get greetings and closings for the language
        greeting_template = self.config['greetings'].get(
            language, self.config['greetings']['English']
        ).get(segment, self.config['greetings']['English']['ASSISTED'])
        
        closing_text = self.config['closings'].get(
            language, self.config['closings']['English']
        ).get(segment, self.config['closings']['English']['ASSISTED'])
        
        # Format greeting
        first_name = customer.get('name', '').split()[0] if customer.get('name') else 'there'
        last_name = customer.get('name', '').split()[-1] if customer.get('name') and len(customer.get('name').split()) > 1 else ''
        
        greeting = greeting_template.format(
            name=first_name,
            first_name=first_name,
            last_name=last_name,
            bank_rep="Sarah",
            time_of_day="morning",
            title="Mr" if customer.get('gender') == 'M' else "Ms"
        )
        
        # Build AI prompt
        prompt = self._build_ai_prompt(
            shared_context.original_letter,
            customer,
            insights,
            strategy,
            content_strategy,
            greeting,
            closing_text,
            language
        )
        
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )
            
            content = response.content[0].text.strip()
            voice_data = self._parse_ai_response(content)
            
            if voice_data:
                return self._create_result_from_data(
                    voice_data, 
                    shared_context,
                    language,
                    "ai_generation"
                )
            
        except Exception as e:
            print(f"  âŒ AI generation error: {e}")
        
        return self._generate_fallback(shared_context)
    
    def _build_ai_prompt(
        self,
        letter: str,
        customer: Dict,
        insights,
        strategy,
        content_strategy,
        greeting: str,
        closing: str,
        language: str
    ) -> str:
        """Build AI prompt for voice script generation"""
        
        # Get critical points
        critical_points = [p.content for p in content_strategy.critical_points[:3]]
        
        return f"""Generate a NATURAL VOICE SCRIPT in {language} for a phone message.

CUSTOMER:
- Name: {customer.get('name')}
- Language: {language} (ENTIRE SCRIPT MUST BE IN {language.upper()})
- Segment: {insights.segment}
- Life Stage: {insights.life_stage}
- Special Context: {customer.get('recent_life_events', 'None')}

KEY POINTS TO CONVEY:
{chr(10).join(['â€¢ ' + point for point in critical_points])}

REQUIREMENTS:
- Language: {language} (NOT ENGLISH unless that's the preferred language)
- Start: "{greeting}"
- End: "{closing}"
- Length: 50-80 words (30-45 seconds spoken)
- Natural conversational tone in {language}
- Reference ONE personal detail
- Sound warm and human

Generate JSON:
{{
    "script": "Complete script in {language}",
    "pace": "slow|normal|fast",
    "emphasis": ["key", "words"],
    "personalizations": ["what was personalized"]
}}

CRITICAL: Write the ENTIRE script in {language}, not English!"""
    
    def _parse_ai_response(self, content: str) -> Optional[Dict]:
        """Parse AI response"""
        content = content.replace('```json', '').replace('```', '').strip()
        
        try:
            return json.loads(content)
        except:
            if '{' in content and '}' in content:
                try:
                    start = content.index('{')
                    end = content.rindex('}') + 1
                    return json.loads(content[start:end])
                except:
                    pass
        return None
    
    def _create_result_from_data(
        self,
        data: Dict,
        shared_context: SharedContext,
        language: str,
        method: str
    ) -> VoiceResult:
        """Create VoiceResult from parsed data"""
        
        script = data.get('script', '')
        word_count = len(script.split())
        pace = data.get('pace', 'normal')
        
        # Calculate duration
        wpm = {'slow': 120, 'normal': 150, 'fast': 180}.get(pace, 150)
        duration = (word_count / wpm) * 60
        
        return VoiceResult(
            content=script,
            duration_estimate=duration,
            word_count=word_count,
            speaking_pace=pace,
            tone_markers=['warm', 'professional'],
            personalization_elements=data.get('personalizations', []),
            emphasis_words=data.get('emphasis', []),
            language=language,
            generation_method=method,
            processing_time=0.0,
            quality_score=0.8,
            audio_file_path=None,
            tts_engine_used="pending"
        )
    
    def _generate_fallback(self, shared_context: SharedContext) -> VoiceResult:
        """Generate fallback script when AI unavailable"""
        
        customer = shared_context.customer_data
        name = customer.get('name', '').split()[0] if customer.get('name') else 'there'
        language = customer.get('preferred_language', 'English')
        segment = shared_context.customer_insights.segment
        
        # Get appropriate greeting and closing
        greeting = self.config['greetings'].get(
            language, self.config['greetings']['English']
        ).get(segment, self.config['greetings']['English']['ASSISTED']).format(
            name=name,
            first_name=name,
            bank_rep="Sarah",
            time_of_day="day",
            title="",
            last_name=""
        )
        
        closing = self.config['closings'].get(
            language, self.config['closings']['English']
        ).get(segment, self.config['closings']['English']['ASSISTED'])
        
        # Build simple script in the appropriate language
        if language == 'Spanish':
            middle = "Tenemos informaciÃ³n importante sobre su cuenta. Por favor, revise su correo para los detalles completos."
        elif language == 'French':
            middle = "Nous avons des informations importantes concernant votre compte. Veuillez vÃ©rifier votre courrier pour les dÃ©tails complets."
        elif language == 'German':
            middle = "Wir haben wichtige Informationen zu Ihrem Konto. Bitte Ã¼berprÃ¼fen Sie Ihre Post fÃ¼r die vollstÃ¤ndigen Details."
        elif language == 'Italian':
            middle = "Abbiamo informazioni importanti sul suo conto. Per favore, controlli la sua posta per i dettagli completi."
        elif language == 'Portuguese':
            middle = "Temos informaÃ§Ãµes importantes sobre sua conta. Por favor, verifique seu correio para os detalhes completos."
        elif language == 'Chinese':
            middle = "æˆ‘ä»¬æœ‰å…³äºŽæ‚¨è´¦æˆ·çš„é‡è¦ä¿¡æ¯ã€‚è¯·æŸ¥çœ‹æ‚¨çš„é‚®ä»¶ä»¥èŽ·å–å®Œæ•´è¯¦æƒ…ã€‚"
        else:
            middle = "We have important information about your account. Please check your mail for the full details."
        
        script = f"{greeting} {middle} {closing}"
        
        word_count = len(script.split())
        duration = (word_count / 150) * 60
        
        return VoiceResult(
            content=script,
            duration_estimate=duration,
            word_count=word_count,
            speaking_pace='normal',
            tone_markers=['professional'],
            personalization_elements=['customer_name', 'language'],
            emphasis_words=['important'],
            language=language,
            generation_method='fallback',
            processing_time=0.0,
            quality_score=0.6,
            audio_file_path=None,
            tts_engine_used="none"
        )
    
    def _create_disabled_result(self, shared_context: SharedContext) -> VoiceResult:
        """Create empty result when voice is disabled"""
        return VoiceResult(
            content="",
            duration_estimate=0.0,
            word_count=0,
            speaking_pace='normal',
            tone_markers=[],
            personalization_elements=[],
            emphasis_words=[],
            language=shared_context.customer_data.get('preferred_language', 'English'),
            generation_method='disabled',
            processing_time=0.0,
            quality_score=0.0,
            audio_file_path=None,
            tts_engine_used="none"
        )
    
    def validate_voice_note(self, result: VoiceResult, shared_context: SharedContext) -> Dict:
        """Validate the generated voice note"""
        validation = {
            'is_valid': True,
            'issues': [],
            'achievements': [],
            'metrics': {
                'duration': f"{result.duration_estimate:.1f}s",
                'language': result.language,
                'has_audio': result.audio_file_path is not None
            }
        }
        
        # Check duration
        if result.duration_estimate < self.config['durations']['min']:
            validation['issues'].append("Too short")
            validation['is_valid'] = False
        elif result.duration_estimate > self.config['durations']['max']:
            validation['issues'].append("Too long")
            validation['is_valid'] = False
        
        # Check language match
        expected_lang = shared_context.customer_data.get('preferred_language', 'English')
        if result.language == expected_lang:
            validation['achievements'].append(f"Correct language: {expected_lang}")
        else:
            validation['issues'].append(f"Wrong language: expected {expected_lang}, got {result.language}")
            validation['is_valid'] = False
        
        # Check audio generation
        if result.audio_file_path:
            validation['achievements'].append(f"Audio generated: {result.tts_engine_used}")
        elif result.generation_method != 'disabled':
            validation['issues'].append("No audio file generated")
        
        return validation

# Convenience function
def generate_smart_voice_note(shared_context: SharedContext, api_key: Optional[str] = None) -> VoiceResult:
    """Generate voice note with audio"""
    generator = SmartVoiceGenerator(api_key=api_key)
    return generator.generate_voice_note(shared_context)